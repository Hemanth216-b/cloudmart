
![Screenshot 2025-03-04 120607](https://github.com/user-attachments/assets/6b2005b8-8093-43d9-8eac-effc012fcd73)

# MultiCloud, DevOps & AI Challenge Creating the E-commerse application called cloudmart
## Step 1: Use Claude to Generate Terraform Code

1. Start a conversation with [Claude](https://claude.ai/).
2. Ask Claude to create Terraform code for an S3 bucket. Use a prompt like:
"Please provide Terraform code to create an S3 bucket in AWS with a unique name."
3. Claude should generate code similar to this:
    
    ```
    provider "aws" {
      region = "us-west-2"  # Replace with your desired region
    }
    
    resource "random_id" "bucket_suffix" {
      byte_length = 8
    }
    
    resource "aws_s3_bucket" "my_bucket" {
      bucket = "my-unique-bucket-name-${random_id.bucket_suffix.hex}"
    
      tags = {
        Name        = "My bucket"
        Environment = "Dev"
      }
    }
    
    resource "aws_s3_bucket_acl" "my_bucket_acl" {
      bucket = aws_s3_bucket.my_bucket.id
      acl    = "private"
    }
    
    ```
    
4. Save this code for use in Step 5.

## Step 2: Create IAM Role for EC2

1. Log in to the AWS Management Console.
2. Navigate to the IAM dashboard.
3. Click "Roles" in the left sidebar, then "Create role".
4. Choose "AWS service" as the trusted entity type and "EC2" as the use case.
5. Search for and attach the "AdministratorAccess" policy.
Note: In a production environment, use a more restricted policy.
6. Name the role "EC2Admin" and provide a description.
7. Review and create the role.

## Step 3: Launch EC2 Instance

1. Go to the EC2 dashboard in the AWS Management Console.
2. Click "Launch Instance".
3. Choose an Amazon Linux 2 AMI.
4. Select a t2.micro instance type.
5. Configure instance details:
    - Network: Default VPC
    - Subnet: Any available
    - Auto-assign Public IP: Enable
    - IAM role: Select "EC2Admin"
6. Keep default storage settings.
7. Add a tag: Key="Name", Value="workstation".
8. Create a security group allowing SSH access from EC2 Connect IP.
9. Review and launch, selecting or creating a key pair.

## Step 4: Connect to EC2 Instance and Install Terraform

1. From the EC2 dashboard, select your "workstation" instance.
2. Click "Connect" and use the "EC2 Instance Connect" method.
3. In the browser-based SSH session, update system packages:
    
    ```
    sudo yum update -y
    
    ```
    
4. Install yum-utils:
    
    ```
    sudo yum install -y yum-utils
    
    ```
    
5. Add HashiCorp repository:
    
    ```
    sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/AmazonLinux/hashicorp.repo
    
    ```
    
6. Install Terraform:
    
    ```
    sudo yum -y install terraform
    
    ```
    
7. Verify installation:
    
    ```
    terraform version
    
    ```
    

## Step 5: Apply Terraform Configuration

1. Create a new directory and navigate to it:
    
    ```
    mkdir terraform-project && cd terraform-project
    
    ```
    
2. Create and open [main.tf](http://main.tf/):
    
    ```
    nano main.tf
    
    ```
    
3. Paste the Terraform code generated by Claude in Step 1.
4. Save and exit the editor (in nano, press Ctrl+X, then Y, then Enter).
5. Initialize Terraform:
    
    ```
    terraform init
    
    ```
    
6. Review the plan:
    
    ```
    terraform plan
    
    ```
    
7. Apply the configuration:
    
    ```
    terraform apply
    
    ```
    
8. Type "yes" when prompted to create the resources.

## Step 6: Verify S3 Bucket Creation

1. Use AWS CLI to list buckets:
    
    ```
    aws s3 ls
    
    ```
    
2. Verify that your new bucket is in the list.

## Step 7: Create the Cloud DynamoDB tables

Remove the S3 lines and add the lines below to create the DynamoDB tables used by CloudMart

```bash
provider "aws" {
  region = "us-east-1"  
}

# Tables DynamoDB
resource "aws_dynamodb_table" "cloudmart_products" {
  name           = "cloudmart-products"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

resource "aws_dynamodb_table" "cloudmart_orders" {
  name           = "cloudmart-orders"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

resource "aws_dynamodb_table" "cloudmart_tickets" {
  name           = "cloudmart-tickets"
  billing_mode   = "PAY_PER_REQUEST"
  hash_key       = "id"

  attribute {
    name = "id"
    type = "S"
  }
}

```

1. Apply the configuration:
    
    ```
    terraform apply
    
    ```
    
2. Type "yes" when prompted to create the resources.

Congratulations! You've successfully used Claude to generate Terraform code, set up an EC2 workstation, installed Terraform, and created an S3 bucket. This completes Day 1 of the MultiCloud DevOps & AI Challenge.
![Screenshot 2025-03-06 194035](https://github.com/user-attachments/assets/4f4ff2ce-eaf4-47e5-a7dd-50d123f7071a)
![Screenshot 2025-03-06 194056](https://github.com/user-attachments/assets/01e8fc38-60f0-422a-8d9e-a2fde1eaa74b)


MultiCloud, DevOps & AI Challenge - Day 2 - Deploying Docker Images for an E-commerce Website with Kubernetes


Part 1 - Docker
Step 1: Install Docker on EC2
Execute the following commands:
```
sudo yum update -y
sudo yum install docker -y
sudo systemctl start docker
sudo docker run hello-world
sudo systemctl enable docker
docker --version
sudo usermod -a -G docker $(whoami)
newgrp docker```
​```
sudo usermod -a -G docker $(whoami)
newgrp docker
```
​
Step 2: Create Docker image for CloudMart
Backend
Create folder and download source code:
```
mkdir -p challenge-day2/backend && cd challenge-day2/backend
wget https://tcb-public-events.s3.amazonaws.com/mdac/resources/day2/cloudmart-backend.zip
unzip cloudmart-backend.zip
```
​
Create .env file:
```
nano .env
```
​
Content of .env:
```
PORT=5000
AWS_REGION=us-east-1
BEDROCK_AGENT_ID=<your-bedrock-agent-id>
BEDROCK_AGENT_ALIAS_ID=<your-bedrock-agent-alias-id>
OPENAI_API_KEY=<your-openai-api-key>
OPENAI_ASSISTANT_ID=<your-openai-assistant-id>
```
​
Create Dockerfile:
```
nano Dockerfile
​```
Content of Dockerfile:
```
FROM node:18
WORKDIR /usr/src/app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 5000
CMD ["npm", "start"]
```
​
Frontend
Create folder and download source code:

```
cd ..
mkdir frontend && cd frontend
wget https://tcb-public-events.s3.amazonaws.com/mdac/resources/day2/cloudmart-frontend.zip
unzip cloudmart-frontend.zip
​```
Create Dockerfile:
```
nano Dockerfile
​
Content of Dockerfile:
FROM node:16-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build
```
```
FROM node:16-alpine
WORKDIR /app
RUN npm install -g serve
COPY --from=build /app/dist /app
ENV PORT=5001
ENV NODE_ENV=production
EXPOSE 5001
CMD ["serve", "-s", ".", "-l", "5001"]
```

​
Part 2 - Kubernetes
Attention: AWS Kubernetes service is not free, so when executing the hands-on below, you will be charged a few cents on your AWS account according to EKS pricing on AWS.
Remember to delete the cluster to avoid unwanted charges. Use the removal section at the end of the doc.
Cluster Setup on AWS Elastic Kubernetes Services (EKS)
Create a user named eksuser with Admin privileges and authenticate with it
aws configure
​
Install the CLI tool eksctl
```
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
sudo cp /tmp/eksctl /usr/bin
eksctl version
```
​
Install the CLI tool kubectl
```
curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.18.9/2020-11-02/bin/linux/amd64/kubectl
chmod +x ./kubectl
mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$PATH:$HOME/bin
echo 'export PATH=$PATH:$HOME/bin' >> ~/.bashrc
kubectl version --short --client
```
​
Create an EKS Cluster
```
eksctl create cluster \
  --name cloudmart \
  --region us-east-1 \
  --nodegroup-name standard-workers \
  --node-type t3.medium \
  --nodes 1 \
  --with-oidc \
  --managed
```
​
Connect to the EKS cluster using the kubectl configuration
```
aws eks update-kubeconfig --name cloudmart
```
​
Verify Cluster Connectivity
```
kubectl get svc
kubectl get nodes
```
​
Create a Role & Service Account to provide pods access to services used by the application (DynamoDB, Bedrock, etc).
```
eksctl create iamserviceaccount \
  --cluster=cloudmart \
  --name=cloudmart-pod-execution-role \
  --role-name CloudMartPodExecutionRole \
  --attach-policy-arn=arn:aws:iam::aws:policy/AdministratorAccess\
  --region us-east-1 \
  --approve
​```

NOTE: In the example above, Admin privileges were used to facilitate educational purposes. Always remember to follow the principle of least privilege in production environments
Backend Deployment on Kubernetes
Create an ECR Repository for the Backend and upload the Docker image to it
Repository name: cloudmart-backend
​
Switch to backend folder
```
cd ../..
cd challenge-day2/backend
​```
Follow the ECR steps to build your Docker image

Create a Kubernetes deployment file (YAML) for the Backend

```
cd ../..
cd challenge-day2/backend
nano cloudmart-backend.yaml
​```
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-backend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-backend-app
  template:
    metadata:
      labels:
        app: cloudmart-backend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-backend-app
        image: public.ecr.aws/l4c0j8h9/cloudmart-backend:latest
        env:
        - name: PORT
          value: "5000"
        - name: AWS_REGION
          value: "us-east-1"
        - name: BEDROCK_AGENT_ID
          value: "xxxxxx"
        - name: BEDROCK_AGENT_ALIAS_ID
          value: "xxxx"
        - name: OPENAI_API_KEY
          value: "xxxxxx"
        - name: OPENAI_ASSISTANT_ID
          value: "xxxx"
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-backend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-backend-app
  ports:
    - protocol: TCP
      port: 5000
      targetPort: 5000
​```

Deploy the Backend on Kubernetes
```
kubectl apply -f cloudmart-backend.yaml
​```

Monitor the status of objects being created and obtain the public IP generated for the API
```
kubectl get pods
kubectl get deployment
kubectl get service
​```

Frontend Deployment on Kubernetes
Preparation
Change the Frontend's .env file to point to the API URL created within Kubernetes obtained by the kubectl get service command
```
cd ../challenge-day2/frontend
nano .env
```
​
Content of .env:
```
VITE_API_BASE_URL=http://<your_url_kubernetes_api>:5000/api
```
​
Create an ECR Repository for the Frontend and upload the Docker image to it
```
Repository name: cloudmart-frontend
​```

Follow the ECR steps to build your Docker image
Create a Kubernetes deployment file (YAML) for the Frontend
```
nano cloudmart-frontend.yaml
```
​
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudmart-frontend-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudmart-frontend-app
  template:
    metadata:
      labels:
        app: cloudmart-frontend-app
    spec:
      serviceAccountName: cloudmart-pod-execution-role
      containers:
      - name: cloudmart-frontend-app
        image: public.ecr.aws/l4c0j8h9/cloudmart-frontend:latest
---

apiVersion: v1
kind: Service
metadata:
  name: cloudmart-frontend-app-service
spec:
  type: LoadBalancer
  selector:
    app: cloudmart-frontend-app
  ports:
    - protocol: TCP
      port: 5001
      targetPort: 5001
​```
Deploy the Frontend on Kubernetes
```
kubectl apply -f cloudmart-frontend.yaml
```
​
Monitor the status of objects being created and obtain the public IP generated for the API
````
kubectl get pods
kubectl get deployment
kubectl get service
​```

Removal
At the end of the hands-on, delete all resources:
If you delete the cluster at the end of the exercise, you'll have to recreate it for the next days. So decide what makes more sense for you: delete the cluster and recreate it every day or keep it and pay for the time it's running. However, don't forget to delete it permanently at the end of the Challenge.
```
kubectl delete service cloudmart-frontend-app-service
kubectl delete deployment cloudmart-frontend-app
kubectl delete service cloudmart-backend-app-service
kubectl delete deployment cloudmart-backend-app

eksctl delete cluster --name cloudmart --region us-east-1
```

![Screenshot 2025-03-05 150518](https://github.com/user-attachments/assets/8c410cc8-ec1b-4638-a082-a4fc9d85acd3)


# Day 3: Building a Robust CI/CD Pipeline in the MultiCloud DevOps & AI Challenge

## Part 1: CI/CD Pipeline Configuration

### Create a free account on GitHub and then create a new repository on GitHub called cloudmart

```docker
cd challenge-day2/frontend
<Run GitHub steps>
```

### Start by pushing the changes in the CloudMart application source code to GitHub

```
git status
git add -A
git commit -m "app sent to repo"
git push
```

### **Configure AWS CodePipeline**

1. **Create a New Pipeline:**
    - Access AWS CodePipeline.
    - Start the 'Create pipeline' process.
    - Name: `cloudmart-cicd-pipeline`
    - Use the GitHub repository `cloudmart-application` as the source.
    - Add the 'cloudmartBuild' project as the build stage.
    - Add the 'cloudmartDeploy' project as the deployment stage.

### Configure **AWS CodeBuild to Build the Docker Image**

1. **Create a Build Project:**
    - Give the project a name (for example, **`cloudmartBuild`**).
    - Connect it to your existing GitHub repository (**`cloudmart-application`**).
    - **Image: amazonlinux2-x86_64-standard:4.0**
    - Configure the environment to support Docker builds. Enable "Enable this flag if you want to build Docker images or want your builds to get elevated privileges"
    - Add the environment variable **ECR_REPO** with the ECR repository URI.
    - For the build specification, use the following **`buildspec.yml`**:

```yaml
version: 0.2
phases:
  install:
    runtime-versions:
      docker: 20
  pre_build:
    commands:
      - echo Logging in to Amazon ECR...
      - aws --version
      - REPOSITORY_URI=$ECR_REPO
      **- aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws/l4c0j8h9**
  build:
    commands:
      - echo Build started on `date`
      - echo Building the Docker image...
      - docker build -t $REPOSITORY_URI:latest .
      - docker tag $REPOSITORY_URI:latest $REPOSITORY_URI:$CODEBUILD_RESOLVED_SOURCE_VERSION
  post_build:
    commands:
      - echo Build completed on `date`
      - echo Pushing the Docker image...
      - docker push $REPOSITORY_URI:latest
      - docker push $REPOSITORY_URI:$CODEBUILD_RESOLVED_SOURCE_VERSION
      - export imageTag=$CODEBUILD_RESOLVED_SOURCE_VERSION
      - printf '[{\"name\":\"cloudmart-app\",\"imageUri\":\"%s\"}]' $REPOSITORY_URI:$imageTag > imagedefinitions.json
      - cat imagedefinitions.json
      - ls -l

env:
  exported-variables: ["imageTag"]

artifacts:
  files:
    - imagedefinitions.json
    - cloudmart-frontend.yaml

```

1. **Add the AmazonElasticContainerRegistryPublicFullAccess permission to ECR in the service role**
- Access the IAM console > Roles.
- Look for the role created "cloudmartBuild" for CodeBuild.
- Add the permission **AmazonElasticContainerRegistryPublicFullAccess**.

### Configure AWS CodeBuild for Application Deployment

**Create a Deployment Project:**

- Repeat the process of creating projects in CodeBuild.
- Give this project a different name (for example, **`cloudmartDeployToProduction`**).
- Configure the environment variables AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY for the credentials of the user **`eks-user`** in Cloud Build, so it can authenticate to the Kubernetes cluster.

*Note: in a real-world production environment, it is recommended to use an IAM role for this purpose. In this practical exercise, we are directly using the credentials of the* **`eks-user`** *to facilitate the process, since our focus is on CI/CD and not on user authentication at this moment. The configuration of this process in EKS is more extensive. Refer to the Reference section and check "Enabling IAM principal access to your cluster"*

- For the deployment specification, use the following **`buildspec.yml`**:

```yaml
version: 0.2

phases:
  install:
    runtime-versions:
      docker: 20
    commands:
      - curl -o kubectl https://amazon-eks.s3.us-west-2.amazonaws.com/1.18.9/2020-11-02/bin/linux/amd64/kubectl
      - chmod +x ./kubectl
      - mv ./kubectl /usr/local/bin
      - kubectl version --short --client
  post_build:
    commands:
      - aws eks update-kubeconfig --region us-east-1 --name cloudmart
      - kubectl get nodes
      - ls
      - IMAGE_URI=$(jq -r '.[0].imageUri' imagedefinitions.json)
      - echo $IMAGE_URI
      - sed -i "s|CONTAINER_IMAGE|$IMAGE_URI|g" cloudmart-frontend.yaml
      - kubectl apply -f cloudmart-frontend.yaml

```

- Replace the image URI on line 18 of the **`cloudmart-frontend.yaml`** files with CONTAINER_IMAGE.
- Commit and push the changes.

```bash
git add -A
git commit -m "replaced image uri with CONTAINER_IMAGE"
git push
```

## **Part 2: Test your CI/CD Pipeline**

1. **Make a Change on GitHub:**
    - Update the application code in the **`cloudmart-application`** repository.
    - File `src/components/MainPage/index.jsx` line 93
    - Commit and push the changes.
    
    ```bash
    git add -A
    git commit -m "changed to Featured Products on CloudMart"
    git push
    ```
    
2. **Observe the Pipeline Execution:**
    - Watch how CodePipeline automatically triggers the build.
    - After the build, the deployment phase should begin.
3. **Verify the Deployment:**
    - Check Kubernetes using **`kubectl`** commands to confirm the application update.
